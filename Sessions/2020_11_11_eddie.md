# Eddie: The University of Edinburgh's high performance computer

As well as this resource there is also information on the [University's wiki page.](https://www.wiki.ed.ac.uk/display/ResearchServices/Eddie)

#### What exactly is Eddie?
A computer cluster with 7000+ cores with up to 3TB of memory. 
It uses an Open Grid Scheduler batch system on Scientific Linux 7. Although that seems a bit like too much information sometimes it can be useful to know that when you're trying to troubleshoot certain problems.

___________________________________

## Amelia's tips for using Eddie:
These contain things that took me hours of googling to figure out how to do, so to save anyone else going through that long, frustrating process I've written them all up here. Some of them are personal preferences in how I've set up using Eddie on my Mac but there's a lot of general things too.

### Table of Contents
1. [Connecting to Eddie](#Connecting-to-Eddie)
2. [Storing data on Eddie and getting files to/from Datastore ](#storing-data-on-eddie-and-getting-files-tofrom-datastore)
3. [Submitting jobs on Eddie](#Submitting-jobs-on-Eddie)
    * [Troubleshooting when your job doesn't work](#troubleshooting-when-your-job-doesnt-work)
4. [Advanced Tips](#advanced-tips)
5. [Some general useful Linux commands](#some-general-useful-linux-commands)
6. [Useful links](#useful-links)


### Connecting to Eddie
First, connect to the university's VPN.
I use Mac OSX so to connect to Eddie I open a bash terminal and type:
```
ssh s1211670@eddie.ecdf.ed.ac.uk
```

* *ssh* is a command that allows us to securely connect to a remote server. 
* *s1211670* is where you put your UUN.
* *@eddie.ecdf.ed.ac.uk* is the name of the remote server.

Additionally, you can use the `-X` or `-Y` flags to forward display to your local computer. **In simple terms you need to do this if you want to plot things** eg. in R using [XQuartz](https://www.xquartz.org/) that's downloaded **and open** on your local computer:

```
ssh -Y s1211670@ed.ac.uk
```

Windows users in the group have said they don't need to specify the -X or -Y flag to view plots.


If you want to see what other flags you can pass to this command type
```
ssh -h
```
**TIP: In general a command followed by `-h` should offer some help on what arguments can be passed to the command.**

"Windows users will need an SSH client, such as PuTTY or MobaXterm. I think Windows 10 has been updated to include an SSH client in the power shell, so people might be able to use that instead." *Thanks Mat for this tip.*

<br/>

### Storing data on Eddie and getting files to/from Datastore 
The datastore and eddie servers are separate servers, so if you save something on one it won't be on the other.
#### Datastore storage

* Backed up more so it's generally better for long term storage of data. 
* Group file path: `igmm/datastore/GenScotDepression/`
* I think the general consensus is to create a folder with your name on in `igmm/datastore/GenScotDepression/users/` to keep this shared space tidy.

#### Eddie storage

* You have a personal storage area on Eddie which is called your scratch directory. It can be found at `/exports/eddie/scratch/UUN` eg:
    ```
    cd /exports/eddie/scratch/UUN
    ```
    This is cleared every month or so. This should be used as a temporary workspace. Whenever working on Eddie, you should copy any input data to your scratch space and do all the processing there, then move any additional output data back to Datastore shared folder at the end. By doing this you can ensure you don't mess things up in the shared group space and also you can be assured only you have access to your scratch space. *Thanks Mat for this tip.*

If you use the `touch` command on file it will update the timestamp, so to keep something for longer than a month you can do this but be careful, don't think of your scratch directory as a long term storage space!



* `home/UUN` is your home directory which has less space than your scratch directory but is not cleared out regularly.
* Group file path: `/exports/igmm/eddie/GenScotDepression/`
* There is less storage space on this shared eddie space than in datastore, so just bear that in mind and if you have any large files that you have finished using for analysis it's probably good practice to remove them from Eddie and keep a copy on datastore instead.

#### Copy files between datastore and eddie

* Log into an interactive staging node on eddie. 
    ```
    qlogin -q staging
    ```

* You should now be able to see the files located in the GenScotDepression group folder on datastore here:
    ```
    /exports/igmm/datastore/GenScotDepression/
    ```
* And files stored on eddie at this path:
    ```
    /exports/igmm/eddie/GenScotDepression/
    ```
* To copy from one to the other use `cp` command, eg:
    ```
    # This copies the file from datastore to eddie:
    cp /exports/igmm/datastore/GenScotDepression/users/amelia/test.sh /exports/igmm/eddie/GenScotDepression/amelia/

    # Or to your scratch space:
    cp /exports/igmm/datastore/GenScotDepression/users/amelia/test.sh /exports/eddie/scratch/<UUN>

    # To copy an entire folder include -r
    cp -r /exports/igmm/datastore/GenScotDepression/users/amelia/test_dir /exports/igmm/eddie/GenScotDepression/amelia/test_dir
    ```
The `cp` command works because our datastore folder is mounted on Eddie. Most shared folders are, but if you find they aren't you can use SFTP to copy folders across.

* Exit the staging node after use.
   ```   
   exit
   ```


<br/>

### Submitting jobs on Eddie

When you want to run code on Eddie you can do this by submitting batch jobs. A batch job is essentially some code that you submit to eddie and then wait for it to finish running, a bit like sourcing an R script. You don't edit it as it is running. If you wanted to test and edit your code you can open an "interactive login session" instead (see [below](#troubleshooting-when-your-job-doesnt-work) on how).

1. Create a job file and edit it. eg:
```
vi jobfile.sh # See below for tips on using vi editor.
# or nano is another text editor which is more intuitive:
nano jobfile.sh
```
Alternatively you can edit a file in a different text editor and copy it across to Eddie.

My job scripts usually contain the following:
```
#!/bin/sh
#$ -N job_name
#$ -e path/to/where/I/want/error/log/to/be/stored
#$ -o path/to/where/I/want/output/log/to/be/stored
#$ -l h_vmem=8G
#$ -pe sharedmem 4
#$ -l h_rt=72:00:00
#$ -m beas 
#$ -M email@ed.ac.uk

# -N is the job name
# -e and -o are the paths where I want the log files for the job to be stored.
# -l h_vmem=8G is the amount of GB I want to request per core.
# -pe sharedmem 4 is the amount of cores I want to request for the job. This will be multiplied by the amount of memory requested for each core, in this case 8x4 = 32GB.
# -l h_rt is the amount of time I want to request for the job. In this case 72 hours. The default (when this option is not specified) is 48 hours. The more time is requested for a job, the longer it may take for Eddie to schedule it for execution. It is always wise to request just one core for a job that does not perform parallel computation as this will speed up the job being scheduled.
# -M email address to send updates on job to
# -m (email sent at: b = beginning, e = end, a = aborted, s = suspended)


# Initialise the environment modules
. /etc/profile.d/modules.sh
# Load R
module load igmm/apps/R/3.6.1
# Run the R script
Rscript --vanilla /exports/igmm/eddie/GenScotDepression/amelia/test.R
```

* This will run my R script called `test.R`
* Most of the flags specified at the top of the job script are optional (eg. you dont need to add your email address or memory required), but specifying a memory request should speed up how long it queues for before running. 
* If specifying the `-pe` flag bear in mind that unless whatever you're running has been set up to use parallel processing (which most R functions are not) then there's no point requesting multiple cores as they won't be used and your job will just likely end up queuing for longer than you need it to.
* `R CMD BATCH` can be used instead of `Rscript`. It's important you load the module for whatever package you want to use, which includes initialising the environment modules.

* "For R only, you will need to make sure any packages you need are installed in your personal R library, which is usually stored in your home folder. Unfortunately, there's not enough space in your home folder on Eddie for lots of packages, or even for some of the bigger packages alone. I store mine on DataStore, copy it to my scratch space on Eddie whenever I need it, and link (using 'ln -s') /home/mharris4/R to /exports/eddie/scratch/mharris4/R." *Thanks Mat for this tip.*


2. Submit the job to Eddie.
```
qsub jobfile.sh
```
For more info on the qsub command see the [man page](http://gridscheduler.sourceforge.net/htmlman/htmlman1/qsub.html). The flags denoted in the job file can also be passed in the command itself. But ensure you put them before the name of the job file you want to submit. 
**It's also important that jobs are submitted from the main eddie command line, not from within an interactive login session.**
eg:
```
qsub -N job_name -l h_vmem = 8G jobfile.sh
```


3. Check status of your job using:
```
qstat
```
Returns the job id (which you should make a note of in case you need to troubleshoot later) and other useful things, like whether your job is queuing `qw` or running `r`. Jobs with larger memory will queue for longer.

<br/>






#### Troubleshooting when your job doesn't work
First thing to do is inspect your log files, which will be saved in the path you specified to the `-o` & `-e` flags of the `qsub` command. "When first trying to get a script working, you can make it output something every so often (after every line if you want) so that you can then check the output file and see exactly where the script went wrong." *Thanks Mat for this tip.*
You can also try `qacct -j <jobid>` where `<jobid` is the number of your job, you'll have to make a note of this when your job is running by using the command `qstat` or it will be in the email if you specified the `-m` & `-M` flags of the qsub command.

If it says `EXIT STATUS = 137` and ` died through signal KILL (9)` then the job didn't have enough memory to run. There's not really an easy way to tell how much memory your job will need. Couple of things to try... 1) If it's a massive job, eg. GWAS, see if you can submit it in chunks as smaller jobs (see below for an example of when I had to do this), 2) Otherwise I will start with submitting the job with 1G memory and then keep doubling this until the job runs.

Other things to try... usually I would start by writing and running code on an **interactive login node** to just check everything is running and then submit it as a job. I would also go onto the interactive login node to troubleshoot why a job hasn't run after looking at the log files for some clues.
This logs us into an interactive node on eddie and opens R: **Really important you do this before running R etc., don't run R or do any heavy memory stuff on the login node that you are automatically on when you ssh into eddie.**
```
qlogin -l h_vmem=32G 
. /etc/profile.d/modules.sh
module load igmm/apps/R/3.6.1
R
```
**It's also really important to exit from this interactive login node when you are finished to free up space for other users.** To do this just type `exit` after you are finished. If your computer crashes or you get that annoying "broken pipe" error message because you lost connection through the VPN then this login node will still be active. It's important to log back into eddie and do: `qstat` and then `qdel -j <job_id>` where `<jobid>` is the id of the `QLOGIN` job. Or `qdel -u <UUN>` to delete all jobs by that user. 



________________

### Advanced tips:
#### Reconnection to an interactive node
*Thanks Aleks for this suggestion:*
"Sometimes connection to Eddie may be lost due to a VPN or Wi-Fi issue. 
In that case the interactive job will still be running and listed when 
executing 'qstat'. It may be possible to reconnect to your interactive 
session if prior to running 'qlogin' you run 'screen' and also take a 
note of the name of the login node where you started the session. Some 
further details on how to use 'screen' are [here](https://www.wiki.ed.ac.uk/display/ResearchServices/Interactive+Sessions) (under the heading 
'Reconnecting to your interactive session')."
* This screen tool looks really useful if like me you want to have a terminal with an R console and a terminal to open and edit scripts in. Apparently screen makes it easy to switch between the two.
* This is probably the best way to use it:
    * Eddie terminal -> screen 0 -> interactive session -> R
                        -> screen 1 -> nano jobfile.sh
                        -> screen 2 -> cd /output/directory

    * As usual, you should close the interactive session when not using it, but you can leave the screen session running. If you just detach from it before logging out of Eddie, then you can reattach to it the next time you log in. Then you'll be straight back to the script you were editing in nano, or the output directory you were monitoring etc.

#### Setting up an SSH key
This is more secure than a password and means you don't have to keep typing your password everytime you log onto Eddie:
```
ssh-keygen (and then just press enter to the next 2-3 prompts)
ssh-copy-id <UUN>@eddie.ecdf.ed.ac.uk (and enter password to connect to Eddie)
```
*Thanks Mat for this tip.*
<br/>

#### Getting variables from your bash environment into an R script
I found this really useful when I wanted to change my script to be submitted as multiple jobs rather than just one. This is the general concept:

* The jobs I ran were as follows:
    ```
    qsub -N GWAS_1 -v x=1 -v y=300000 job_GWAS.sh
    qsub -N GWAS_2 -v x=300001 -v y=600000 job_GWAS.sh
    qsub -N GWAS_3 -v x=600001 -v y=900000 job_GWAS.sh
    ```
    Where I wanted to run the same job_GWAS.sh script but with different variables submitted to R. ie the x and y variables (which in this case specified different rows of a dataframe). The `-v` flag specifies these variables which will now exist in the bash environment that the job script is run in. You need a new `-v` flag for each new variable.

    
* My job script looked like this:
    ```
    #!/bin/sh
    #$ -e /exports/igmm/eddie/GenScotDepression/amelia/PRS_project/Cross-disorder/job_logs
    #$ -o /exports/igmm/eddie/GenScotDepression/amelia/PRS_project/Cross-disorder/job_logs
    #$ -l h_vmem=4G
    #$ -m beas
    #$ -M edmondson.staita@gmail.com

    # Initialise the environment modules
    . /etc/profile.d/modules.sh
    module load igmm/apps/R/3.6.1

    Rscript --vanilla /exports/igmm/eddie/GenScotDepression/amelia/PRS_project/Cross-disorder/Scripts/common_factorGWAS.R ${x} ${y}
    ```
    The important bits here are `${x}` and `${y}`, and the fact these are listed after I specified the R script to run. The order you list them here are the order they are read in R (which is important).

    "You can also pass variables to a job script as you would to any other bash script, e.g. `qsub jobfile.sh 1 3000`, then use the variables `$1` and `$2` rather than `$x` and `$y`." *Thanks Mat for this tip.*

* My R script contained the code:
    ```
    ##First read in the arguments listed at the command line in bash
    args <- commandArgs(trailingOnly=TRUE) # This is the amazing command that reads variables stored in your bash environment into R.
    # Separate them out using their index (this is a bit error prone as if you mess up the order or there are more than 2 bash variables you'll get the wrong input, there's probably more elegant ways to do this).
    x <- as.numeric(args[[1]])
    y <- as.numeric(args[[2]])

    # Run the common factor GWAS on a subset of SNPs (from row x to row y of my p_sumstas dataframe).
    # x and y are specifed by the bash job script.
    pfactor <- commonfactorGWAS(covstruc = LDSCoutput, SNPs = p_sumstats[x:y,], estimation = "DWLS", cores = NULL, toler = FALSE, SNPSE = FALSE, parallel = FALSE, Output = NULL,GC="standard",MPI=FALSE)
    ```

* You could also use loops when submitting jobs. The following will submit the same job 1000 times with a different input each time. Running loads of little jobs simultaneously is what Eddie is good for:
    ```
    for N in $(seq 1 1000)
    do qsub jobfile.sh $N
    done
    ```


<br/>

#### Mount Eddie to your local machine to browse and edit files
*Thanks Aleks for this tip*:
"On Linux it is also possible to connect to Eddie with the file browser 
using SFTP - simply enter 
`sftp://<username>@eddie.ecdf.ed.ac.uk/exports/eddie/home/<username>` into 
the file browser address bar (or use 'Connect to Server' option), enter 
the login details and Eddie will be mounted and available to explore 
like a local filesystem where you can move and copy files. It is also 
possible to open and edit text files from Eddie this way directly on 
your local computer.

On Mac and Windows it slightly more complicated and requires installing 
additional software, however I have been able to find these options: [FUSE and SSHFS](https://blog.earth-works.com/2015/08/18/how-to-mount-remote-sftp-ssh-file-system-on-your-mac/) for Mac and [WinSCP](https://winscp.net/eng/docs/task_edit) for Windows." 

#### Using Sublime text editor from Eddie by creating an ssh tunnel (yes, it's as exciting as it sounds!)

As an alternative to Aleks' suggestion above to open and edit remote files using a local text editor called sublime:

* If you don't want to do this because it sounds complicated etc. then `nano` is also a really good text editor. eg. `nano filename.R`

```
# On your local machine find your .ssh folder and edit the config file. eg.:
nano ~/.ssh/config
# Insert the following:
HostName s1211670@eddie.ecdf.ed.ac.uk # Change to your UUN
RemoteForward 52698 127.0.0.1:52698
# exit nano 
```
Install Sublime on your local machine. Then install rsub package on your local Sublime (using Sublime's package manager).
<br/>
Then go back to your bash terminal on your local computer and log into eddie using:
```
# Install rmate on Eddie (this talks to rsub through the SHH tunnel)
Log into to eddie (note the additional `-R`)
ssh -R 52698:localhost:52698 s1211670@eddie.ecdf.ed.ac.uk

wget -O /exports/igmm/eddie/GenScotDepression/amelia/packages/rsub \https://raw.github.com/aurora/rmate/master/rmate
chmod a+x /exports/igmm/eddie/GenScotDepression/amelia/packages/rsub #Changes permissions of folder.

# Edit your bash profile
nano ~/.bash_profile
# Add path to rsub command by copying and pasting this:
export PATH=$PATH:/exports/igmm/eddie/GenScotDepression/amelia/packages/
# exit nano

# Opens text file in sublime.
cd /exports/igmm/eddie/GenScotDepression/amelia/PRS_project/Cross-disorder/Scripts/
rsub common_factor.R
```

<br/>

#### Editing your bash profile, (and then accidentally breaking it so eddie wouldn't open any more, oops)

I once edited my bash profile with something that didn't work and then couldn't log into eddie! Luckily I could do
```
ssh -t s1211670@eddie.ecdf.ed.ac.uk /bin/sh
nano ~/.bash_profile
```
and remove the broken code.


___________________
### Some general useful Linux commands

* `cd path/to/directory/you/want/to/change/to` Change directory.
* `cd ../` Change directory by moving back one folder.
* `pwd` Print your working directory.
* `nano filename` - text editor, more intuitive than `vi`.
* `vi filename` Open a file in vi text editor (useful to have a quick look and edit a small file).
    - Press "i" on your keyboard to insert text.
    - Press "esc" when you have finished, followed by ":wq", the "w" means "write" and the "q" means "quit".
* `less filename` View contents of file. Press "q" when finished to return to command line.
* `cat` Prints contents of file in terminal. Not so good for really large files!
* Saving bash variables and printing them in the terminal, eg.:
    ```
    $ x=2
    $ echo ${x}
    2
    ```
* `wc -l file.txt` Counts number of lines in file.txt


_____________
### Useful links
* [job chaining](https://www.nics.tennessee.edu/computing-resources/running-jobs/job-chaining)






