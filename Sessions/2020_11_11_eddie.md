# Eddie: The University of Edinburgh's high performance computer

As well as this resource there is also information on the [University's wiki page.](https://www.wiki.ed.ac.uk/display/ResearchServices/Eddie) including their course notes [here](https://www.wiki.ed.ac.uk/pages/viewpage.action?spaceKey=ResearchServices&title=Introduction+to+Eddie). UCL also have a nice page explaining how to use [HPCs](https://www.rc.ucl.ac.uk/docs/howto/#how-do-i-log-in).

#### What exactly is Eddie?
A computer cluster with 7000+ cores with up to 3TB of memory. 
It uses an Open Grid Scheduler batch system on Scientific Linux 7. Although that seems a bit like too much information sometimes it can be useful to know that when you're trying to troubleshoot certain problems.

#### VPN
To be able to use Eddie you need to be on the University's network. You can do this remotely by connecting to the VPN.
Please see the [University's website](https://www.ed.ac.uk/information-services/computing/desktop-personal/vpn) for how to do this.

Window's users also see [this guide](https://teams.microsoft.com/l/file/3FF054B9-738F-40F0-AD4D-523D2B6CB067?tenantId=2e9f06b0-1669-4589-8789-10a06934dc61&fileType=docx&objectUrl=https%3A%2F%2Fuoe.sharepoint.com%2Fsites%2FDepressionResearch%2FShared%20Documents%2FCoding%20club%2FConnecting%20to%20DataStore%20through%20VPN.docx&baseUrl=https%3A%2F%2Fuoe.sharepoint.com%2Fsites%2FDepressionResearch&serviceName=teams&threadId=19:c424c64008714e978593e70c6171f95a@thread.tacv2&groupId=2fc34ec6-881a-4474-8731-d36e84b8ec9e) by Laura Klinkhamer in our group.

#### Mac or Windows?
The set up for using Eddie is slightly different for Windows and Mac users. If you get stuck here's a [list](https://teams.microsoft.com/l/file/E1EF1987-6F26-4F52-873C-9622CB4A26E0?tenantId=2e9f06b0-1669-4589-8789-10a06934dc61&fileType=xlsx&objectUrl=https%3A%2F%2Fuoe.sharepoint.com%2Fsites%2FDepressionResearch%2FShared%20Documents%2FCoding%20club%2FOS_everyone_works_on.xlsx&baseUrl=https%3A%2F%2Fuoe.sharepoint.com%2Fsites%2FDepressionResearch&serviceName=teams&threadId=19:c424c64008714e978593e70c6171f95a@thread.tacv2&groupId=2fc34ec6-881a-4474-8731-d36e84b8ec9e) of people in the group, what OS they use and whether they are happy to be approached to help/
___________________________________

## Amelia's tips for using Eddie:
These contain things that took me hours of googling to figure out how to do, so to save anyone else going through that long, frustrating process I've written them all up here. Some of them are personal preferences in how I've set up using Eddie on my Mac but there's a lot of general things too.

### Table of Contents
1. [Connecting to Eddie](#Connecting-to-Eddie)
2. [Storing data on Eddie and getting files to/from Datastore ](#storing-data-on-eddie-and-getting-files-tofrom-datastore)
3. [Submitting jobs on Eddie](#Submitting-jobs-on-Eddie)
    * [Troubleshooting when your job doesn't work](#troubleshooting-when-your-job-doesnt-work)
4. [Aug 2024 Update of Eddie to Rocky Linux](#aug-2024-update-of-eddie-to-rocky-linux)
5. [Advanced Tips](#advanced-tips)
6. [Some general useful Linux commands](#some-general-useful-linux-commands)
7. [Useful links](#useful-links)


### Connecting to Eddie
First, connect to the university's VPN.
I use Mac OSX so to connect to Eddie I open a bash terminal and type:
```
ssh s1211670@eddie.ecdf.ed.ac.uk
```

* *ssh* is a command that allows us to securely connect to a remote server. 
* *s1211670* is where you put your UUN. This begins with "s" for a student id, or if you're staff your UUN may contain your surname.
* *@eddie.ecdf.ed.ac.uk* is the name of the remote server.

Additionally, you can use the `-X` or `-Y` flags to forward display to your local computer. **In simple terms you need to do this if you want to plot things** eg. in R using [XQuartz](https://www.xquartz.org/) that's downloaded **and open** on your local computer:

```
ssh -X s1211670@eddie.ecdf.ed.ac.uk
```

Windows users in the group have said they don't need to specify the -X or -Y flag to view plots.

You also need X forwarding to open R studio in an interactive session:
```
module load igmm/apps/RStudio
Rstudio
```

The following will let you login to eddie on a specific login node.
```
ssh <username>@loginXX-ext.ecdf.ed.ac.uk to connect to a specific login node
```

If you want to see what other flags you can pass to this command type
```
ssh -h
```
**TIP: In general a command followed by `-h` should offer some help on what arguments can be passed to the command.**

"Windows users will need an SSH client, such as PuTTY or MobaXterm. I think Windows 10 has been updated to include an SSH client in the power shell, so people might be able to use that instead." *Thanks Mat for this tip.*

<br/>

### Storing data on Eddie and getting files to/from Datastore 
The datastore and eddie servers are separate servers, so if you save something on one it won't be on the other.
#### Datastore storage

* Backed up more so it's generally better for long term storage of data. 
* Group file path: `igmm/datastore/GenScotDepression/`
* I think the general consensus is to create a folder with your name on in `igmm/datastore/GenScotDepression/users/` to keep this shared space tidy.

#### Eddie storage

* You have a personal storage area on Eddie which is called your scratch directory. It can be found at `/exports/eddie/scratch/UUN` eg:
    ```
    cd /exports/eddie/scratch/UUN
    ```
    This is cleared every month or so. This should be used as a temporary workspace. Whenever working on Eddie, you should copy any input data to your scratch space and do all the processing there, then move any additional output data back to Datastore shared folder at the end. By doing this you can ensure you don't mess things up in the shared group space and also you can be assured only you have access to your scratch space. *Thanks Mat for this tip.*

If you use the `touch` command on file it will update the timestamp, so to keep something for longer than a month you can do this but be careful, don't think of your scratch directory as a long term storage space!



* `home/UUN` is your home directory which has less space than your scratch directory but is not cleared out regularly.
* Group file path: `/exports/igmm/eddie/GenScotDepression/`
* There is less storage space on this shared eddie space than in datastore, so just bear that in mind and if you have any large files that you have finished using for analysis it's probably good practice to remove them from Eddie and keep a copy on datastore instead.

### Find an rds file matching a UKB field ID:
If you want to know which files contain a specific field ID you can do the following to get an idea of where to search:
In this example I want to find the rds files that contains the UKB field ID "30710"	(C-reactive protein).

```
# ssh onto Eddie - you need to be in a linux environment for the grep command to work - it's slightly different on macs.
# go onto a staging node to get access to datastore server as well as eddie:
qlogin -q staging
# Change directory to roughly where you think the files might be contained:
cd /exports/igmm/datastore/GenScotDepression/data/ukb/phenotypes/
# Search html files (which have a corresponding rds file) to match your field id of interest:
find *.html | grep -Rl "id=30710"
```
At the moment this returns a list of html files containing any matches for that field id. But as far as I'm aware these html files have a corresponding rds file (which is binary hence why you can't search it using grep) containing the data you want. So at least if gives you a bit of an indication of where to look.
If anyone has a way to improve this futher, eg. with an additional pipe using awk or sed please feel free to edit this!


#### Copy files between datastore and eddie

* Log into an interactive staging node on eddie (note this is different to a normal interactive node) 
    ```
    qlogin -q staging
    ```

* You should now be able to see the files located in the GenScotDepression group folder on datastore here:
    ```
    /exports/igmm/datastore/GenScotDepression/
    ```
* And files stored on eddie at this path:
    ```
    /exports/igmm/eddie/GenScotDepression/
    ```
* To copy from one to the other use `cp` command, eg:
    ```
    # This copies the file from datastore to eddie:
    cp /exports/igmm/datastore/GenScotDepression/users/amelia/test.sh /exports/igmm/eddie/GenScotDepression/amelia/

    # Or to your scratch space:
    cp /exports/igmm/datastore/GenScotDepression/users/amelia/test.sh /exports/eddie/scratch/<UUN>

    # To copy an entire folder include -r
    cp -r /exports/igmm/datastore/GenScotDepression/users/amelia/test_dir /exports/igmm/eddie/GenScotDepression/amelia/test_dir
    ```
The `cp` command works because our datastore folder is mounted on Eddie. Most shared folders are, but if you find they aren't you can use SFTP to copy folders across.

* Exit the staging node after use.
   ```   
   exit
   ```


<br/>

### Submitting jobs on Eddie

When you want to run code on Eddie you can do this by submitting batch jobs. A batch job is essentially some code that you submit to eddie and then wait for it to finish running, a bit like sourcing an R script. You don't edit it as it is running. If you wanted to test and edit your code you can open an "interactive login session" instead (see [below](#troubleshooting-when-your-job-doesnt-work) on how).
See Shen's "basic scripts for submitting jobs on eddie" [here](https://github.com/xshen796/CodingClubPsych/tree/master/Eddie_demo) too.

1. Create a job file and edit it. eg:
```
vi jobfile.sh # See below for tips on using vi editor.
# or nano is another text editor which is more intuitive:
nano jobfile.sh
```
Alternatively you can edit a file in a different text editor and copy it across to Eddie.

My job scripts usually contain the following:
```
#$ -N job_name
#$ -e path/to/where/I/want/error/log/to/be/stored
#$ -o path/to/where/I/want/output/log/to/be/stored
#$ -l h_vmem=8G
#$ -pe sharedmem 4
#$ -l h_rt=48:00:00
#$ -m beas 
#$ -M email@ed.ac.uk

# -N is the job name
# -e and -o are the paths where I want the log files for the job to be stored.
# -l h_vmem=8G is the amount of GB I want to request per core.
# -pe sharedmem 4 is the amount of cores I want to request for the job. This will be multiplied by the amount of memory requested for each core, in this case 8x4 = 32GB.
# -l h_rt is the amount of time I want to request for the job. In this case 72 hours. The default (when this option is not specified) is 48 hours. The more time is requested for a job, the longer it may take for Eddie to schedule it for execution. It is always wise to request just one core for a job that does not perform parallel computation as this will speed up the job being scheduled.
# -M email address to send updates on job to
# -m (email sent at: b = beginning, e = end, a = aborted, s = suspended)


# Initialise the environment modules
. /etc/profile.d/modules.sh
# Load R
module load igmm/apps/R/3.6.1
# Run the R script
Rscript --vanilla /exports/igmm/eddie/GenScotDepression/amelia/test.R
```

* This will run my R script called `test.R`
* Most of the flags specified at the top of the job script are optional (eg. you dont need to add your email address or memory required), but specifying a memory request should speed up how long it queues for before running. 
* If specifying the `-pe` flag bear in mind that unless whatever you're running has been set up to use parallel processing (which most R functions are not) then there's no point requesting multiple cores as they won't be used and your job will just likely end up queuing for longer than you need it to.
* `R CMD BATCH` can be used instead of `Rscript`. It's important you load the module for whatever package you want to use, which includes initialising the environment modules.

* "For R only, you will need to make sure any packages you need are installed in your personal R library, which is usually stored in your home folder. Unfortunately, there's not enough space in your home folder on Eddie for lots of packages, or even for some of the bigger packages alone. I store mine on DataStore, copy it to my scratch space on Eddie whenever I need it, and link (using 'ln -s') /home/mharris4/R to /exports/eddie/scratch/mharris4/R." *Thanks Mat for this tip.*


2. Submit the job to Eddie.
```
qsub jobfile.sh
```
For more info on the qsub command see the [man page](http://gridscheduler.sourceforge.net/htmlman/htmlman1/qsub.html). The flags denoted in the job file can also be passed in the command itself. But ensure you put them before the name of the job file you want to submit. 
**It's also important that jobs are submitted from the main eddie command line, not from within an interactive login session.**
eg:
```
qsub -N job_name -l h_vmem = 8G jobfile.sh
```


3. Check status of your job using:
```
qstat
```
Returns the job id (which you should make a note of in case you need to troubleshoot later) and other useful things, like whether your job is queuing `qw` or running `r`. Jobs with larger memory will queue for longer.

<br/>






#### Troubleshooting when your job doesn't work
First thing to do is inspect your log files, which will be saved in the path you specified to the `-o` & `-e` flags of the `qsub` command. "When first trying to get a script working, you can make it output something every so often (after every line if you want) so that you can then check the output file and see exactly where the script went wrong." *Thanks Mat for this tip.*
You can also try `qacct -j <jobid>` where `<jobid` is the number of your job, you'll have to make a note of this when your job is running by using the command `qstat` or it will be in the email if you specified the `-m` & `-M` flags of the qsub command.

* **Insufficient memory**

If it says `EXIT STATUS = 137` and ` died through signal KILL (9)` then the job didn't have enough memory to run. There's not really an easy way to tell how much memory your job will need. Things to try... 

1) If it's a massive job, eg. GWAS, see if you can submit it in chunks as smaller jobs (see below for an example of when I had to do this)

2) Otherwise I will start with submitting the job with 1G memory and then keep doubling this until the job runs.

3) Once you are requesting more than 32G of memory it is worth requesting multiple cores e.g. 32G on 2 nodes rather than 64G on one node. This is because there are far more low and middle memory nodes than large memory nodes. Most programs can be run on multiple nodes (e.g. SBayesR) but if not your jobs will fail and you'll just have to queue for longer

* **Windows/Unix incompatibility**

If it says `error state -1` it may be that the problem is Windows/Unix compatibility (specifically end of line settings). This can arise if you create the file in Windows (even using a code editor if settings aren't for Unix) and then copy it over to your Eddie scratch space. A conversion from DOS is done which can introduce problems. You can get round this by a) making a new jobfile using a text editor within Eddie e.g. `nano jobfile.sh`, and either typing direct or copying and pasting your (Windows) code in. b) You can run `dos2unixjobfile.sh` within Eddie. c) Altering your code editor settings (line endings should be "LF" for Unix).

* **More on error codes**

The error codes should go from 0 to 255 and follow normal shell conventions.  In the case that the command exits abnormally, a value of 128 is added to the value of the command to make up the exit status. For example: If a job dies through signal 9 (SIGKILL) then the exit status becomes 128 + 9 = 137. Common shell conventions for Linux are: 
* 1 - Catchall for general errors
* 2 - Misuse of shell builtins (according to Bash documentation)
* 126 - Command invoked cannot execute
* 127 - “command not found”
* 128 - Invalid argument to exit
* 128+n - Fatal error signal “n”
* 130 - Script terminated by Control-C
* 255\* - Exit status out of range

[A fuller list is available here](https://unix.stackexchange.com/questions/326766/what-are-the-standard-error-codes-in-linux)


* **Try on an interactive node**

Other things to try... usually I would start by writing and running code on an **interactive login node** to just check everything is running and then submit it as a job. I would also go onto the interactive login node to troubleshoot why a job hasn't run after looking at the log files for some clues.
This logs us into an interactive node on eddie and opens R: **Really important you do this before running R etc., don't run R or do any heavy memory stuff on the login node that you are automatically on when you ssh into eddie.**
```
qlogin -l h_vmem=32G 
. /etc/profile.d/modules.sh
module load igmm/apps/R/3.6.1
R
```
**It's also really important to exit from this interactive login node when you are finished to free up space for other users.** To do this just type `exit` after you are finished. If your computer crashes or you get that annoying "broken pipe" error message because you lost connection through the VPN then this login node will still be active. It's important to log back into eddie and do: `qstat` and then `qdel -j <job_id>` where `<jobid>` is the id of the `QLOGIN` job. Or `qdel -u <UUN>` to delete all jobs by that user. 

________________

### Aug 2024: Update of Eddie to Rocky Linux

#### Interactive sessions (qlogin)

Just add the -l rl9=true option to your regular options when requesting the qlogin session.
For example, if you are requesting a qlogin session with 4GB of virtual memory and 24 hours of runtime, you should run:

qlogin -l h_vmem=4G -l h_rt=24:00:00 -l rl9=true

Please refer to our Interactive Sessions wiki page if you need more information on interactive (qlogin) sessions: https://www.wiki.ed.ac.uk/display/ResearchServices/Interactive+Sessions

#### Job submission (qsub)

Just add the -l rl9=true option to the scheduler options at the top of your job submission script or on the command line when submitting your job.
For example, for a job requesting 4 cores with 4GB of virtual memory per core and 24 hours of runtime, your scheduler options would look like this:

#$ -pe sharedmem 4
#$ -l h_vmem=4G
#$ -l h_rt=24:00:00
#$ -l rl9=true

Please refer to the Job Submission wiki page if you need more information on job submission: https://www.wiki.ed.ac.uk/display/ResearchServices/Job+Submission


#### What is different on Rocky Linux? Applications

So what kind of adjustments will you have to make to your jobs? The main difference between Scientific Linux 7 and Rocky Linux 9 nodes is the applications, libraries, compilers and tools  (and versions of these) that are installed on the nodes or as modules. 

We have currently installed some of the basic and most used applications and tools as modules: anaconda, R, openmpi, intel compilers, cuda, singularity.

Local computing support teams (e.g. Roslin, IGC) have also been asked to install applications for their users as community modules.

All modules that have currently been installed can be viewed with:

module available

after logging into a Rocky Linux node via an interactive session. More information on how to use the 'module' command can be seen here: https://www.wiki.ed.ac.uk/display/ResearchServices/Applications

________________

### Advanced tips:
#### Reconnection to an interactive node
*Thanks Aleks for this suggestion:*
"Sometimes connection to Eddie may be lost due to a VPN or Wi-Fi issue. 
In that case the interactive job will still be running and listed when 
executing 'qstat'. It may be possible to reconnect to your interactive 
session if prior to running 'qlogin' you run 'screen' and also take a 
note of the name of the login node where you started the session. Some 
further details on how to use 'screen' are [here](https://www.wiki.ed.ac.uk/display/ResearchServices/Interactive+Sessions) (under the heading 
'Reconnecting to your interactive session')."
* This screen tool looks really useful if like me you want to have a terminal with an R console and a terminal to open and edit scripts in. Apparently screen makes it easy to switch between the two.
* This is probably the best way to use it:
    * Eddie terminal -> screen 0 -> interactive session -> R
                        -> screen 1 -> nano jobfile.sh
                        -> screen 2 -> cd /output/directory

    * As usual, you should close the interactive session when not using it, but you can leave the screen session running. If you just detach from it before logging out of Eddie, then you can reattach to it the next time you log in. Then you'll be straight back to the script you were editing in nano, or the output directory you were monitoring etc.

#### Setting up an SSH key
This is more secure than a password and means you don't have to keep typing your password everytime you log onto Eddie. Further info on the wiki: https://www.wiki.ed.ac.uk/display/ResearchServices/SSH+keys+best+practice+guide 
```
ssh-keygen (and then just press enter to the next 2-3 prompts)
ssh-copy-id <UUN>@eddie.ecdf.ed.ac.uk (and enter password to connect to Eddie)
```
*Thanks Mat for this tip.*
<br/>

#### Getting variables from your bash environment into an R script
I found this really useful when I wanted to change my script to be submitted as multiple jobs rather than just one. This is the general concept:

* The jobs I ran were as follows:
    ```
    qsub -N GWAS_1 -v x=1 -v y=300000 job_GWAS.sh
    qsub -N GWAS_2 -v x=300001 -v y=600000 job_GWAS.sh
    qsub -N GWAS_3 -v x=600001 -v y=900000 job_GWAS.sh
    ```
    Where I wanted to run the same job_GWAS.sh script but with different variables submitted to R. ie the x and y variables (which in this case specified different rows of a dataframe). The `-v` flag specifies these variables which will now exist in the bash environment that the job script is run in. You need a new `-v` flag for each new variable.

    
* My job script looked like this:
    ```
    #!/bin/sh
    #$ -e /exports/igmm/eddie/GenScotDepression/amelia/PRS_project/Cross-disorder/job_logs
    #$ -o /exports/igmm/eddie/GenScotDepression/amelia/PRS_project/Cross-disorder/job_logs
    #$ -l h_vmem=4G
    #$ -m beas
    #$ -M edmondson.staita@gmail.com

    # Initialise the environment modules
    . /etc/profile.d/modules.sh
    module load igmm/apps/R/3.6.1

    Rscript --vanilla /exports/igmm/eddie/GenScotDepression/amelia/PRS_project/Cross-disorder/Scripts/common_factorGWAS.R ${x} ${y}
    ```
    The important bits here are `${x}` and `${y}`, and the fact these are listed after I specified the R script to run. The order you list them here are the order they are read in R (which is important).

    "You can also pass variables to a job script as you would to any other bash script, e.g. `qsub jobfile.sh 1 3000`, then use the variables `$1` and `$2` rather than `$x` and `$y`." *Thanks Mat for this tip.*

* My R script contained the code:
    ```
    ##First read in the arguments listed at the command line in bash
    args <- commandArgs(trailingOnly=TRUE) # This is the amazing command that reads variables stored in your bash environment into R.
    # Separate them out using their index (this is a bit error prone as if you mess up the order or there are more than 2 bash variables you'll get the wrong input, there's probably more elegant ways to do this).
    x <- as.numeric(args[[1]])
    y <- as.numeric(args[[2]])

    # Run the common factor GWAS on a subset of SNPs (from row x to row y of my p_sumstas dataframe).
    # x and y are specifed by the bash job script.
    pfactor <- commonfactorGWAS(covstruc = LDSCoutput, SNPs = p_sumstats[x:y,], estimation = "DWLS", cores = NULL, toler = FALSE, SNPSE = FALSE, parallel = FALSE, Output = NULL,GC="standard",MPI=FALSE)
    ```

* You could also use loops when submitting jobs. The following will submit the same job 1000 times with a different input each time. Running loads of little jobs simultaneously is what Eddie is good for:
    ```
    for N in $(seq 1 1000)
    do qsub jobfile.sh $N
    done
    ```


<br/>

#### Mount Eddie to your local machine to browse and edit files
*Thanks Aleks for this tip*:
"On Linux it is also possible to connect to Eddie with the file browser 
using SFTP - simply enter 
`sftp://<username>@eddie.ecdf.ed.ac.uk/exports/eddie/home/<username>` into 
the file browser address bar (or use 'Connect to Server' option), enter 
the login details and Eddie will be mounted and available to explore 
like a local filesystem where you can move and copy files. It is also 
possible to open and edit text files from Eddie this way directly on 
your local computer.

On Mac and Windows it slightly more complicated and requires installing 
additional software, however I have been able to find these options: [FUSE and SSHFS](https://blog.earth-works.com/2015/08/18/how-to-mount-remote-sftp-ssh-file-system-on-your-mac/) for Mac and [WinSCP](https://winscp.net/eng/docs/task_edit) for Windows." 

There's also MobaXterm which can be used for similar file management: https://www.wiki.ed.ac.uk/display/ResearchServices/Quickstart 

#### Using Sublime text editor from Eddie by creating an ssh tunnel (yes, it's as exciting as it sounds!)

As an alternative to Aleks' suggestion above to open and edit remote files using a local text editor called sublime:

* If you don't want to do this because it sounds complicated etc. then `nano` is also a really good text editor. eg. `nano filename.R`

```
# On your local machine find your .ssh folder and edit the config file. eg.:
nano ~/.ssh/config
# Insert the following:
HostName s1211670@eddie.ecdf.ed.ac.uk # Change to your UUN
RemoteForward 52698 127.0.0.1:52698
# exit nano 
```
Install Sublime on your local machine. Then install rsub package on your local Sublime (using Sublime's package manager).
<br/>
Then go back to your bash terminal on your local computer and log into eddie using:
```
# Install rmate on Eddie (this talks to rsub through the SHH tunnel)
Log into to eddie (note the additional `-R`)
ssh -R 52698:localhost:52698 s1211670@eddie.ecdf.ed.ac.uk

wget -O /exports/igmm/eddie/GenScotDepression/amelia/packages/rsub \https://raw.github.com/aurora/rmate/master/rmate
chmod a+x /exports/igmm/eddie/GenScotDepression/amelia/packages/rsub #Changes permissions of folder.

# Edit your bash profile
nano ~/.bash_profile
# Add path to rsub command by copying and pasting this:
export PATH=$PATH:/exports/igmm/eddie/GenScotDepression/amelia/packages/
# exit nano

# Opens text file in sublime.
cd /exports/igmm/eddie/GenScotDepression/amelia/PRS_project/Cross-disorder/Scripts/
rsub common_factor.R
```

#### Using Eddie on VSCode

Please see some nice instructions on this here: https://git.ecdf.ed.ac.uk/-/snippets/130 



#### Editing your bash profile, (and then accidentally breaking it so eddie wouldn't open any more, oops)

I once edited my bash profile with something that didn't work and then couldn't log into eddie! Luckily I could do
```
ssh -t s1211670@eddie.ecdf.ed.ac.uk /bin/sh
nano ~/.bash_profile
```
and remove the broken code.

#### Job chaining
If you want jobs scripts to run one after another, ie. job2.sh depends on output of job1.sh then you can do:
```
qsub -N job1 job1.sh
qsub -N job2 -hold_jid job1 job2.sh
```

This also works if you have many jobs named with the same prefix. 
eg: prep1.sh and prep2.sh are independent of each other, but job3.sh depends on the output of prep1.sh and prep2.sh to run.
```
qsub -N prep_step1 prep1.sh
qsub -N prep_step2 prep2.sh
qsub -N job3 -hold_jid prep_* job3.sh
```

#### Job arrays
This is good for when you have the same job script you want to run over many different inputs, eg. 1-22 chromosomes.
For learning about job arrays see this explanation [here](https://info.hpc.sussex.ac.uk/hpc-guide/how-to/array.html): "The naive thing to do is to write a script that does a qsub many times. The reason for this is that each invocation creates a separate job, which has it’s own job id, has it’s own job priority, have it’s own entry in qstat, and be considered independently of all other jobs by the scheduler." 

___________________
### Some general useful Linux commands

* `cd path/to/directory/you/want/to/change/to` Change directory.
* `cd ../` Change directory by moving back one folder.
* `pwd` Print your working directory.
* `nano filename` - text editor, more intuitive than `vi`.
* `vi filename` Open a file in vi text editor (useful to have a quick look and edit a small file).
    - Press "i" on your keyboard to insert text.
    - Press "esc" when you have finished, followed by ":wq", the "w" means "write" and the "q" means "quit".
* `less filename` View contents of file. Press "q" when finished to return to command line.
* `cat` Prints contents of file in terminal. Not so good for really large files!
* Saving bash variables and printing them in the terminal, eg.:
    ```
    $ x=2
    $ echo ${x}
    2
    ```
* `wc -l file.txt` Counts number of lines in file.txt



_____________
### Useful links
* [Symbolic Links](https://www.freecodecamp.org/news/symlink-tutorial-in-linux-how-to-create-and-remove-a-symbolic-link/)






